{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f7a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mistral_inference in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.6.0)\n",
      "Requirement already satisfied: fire>=0.6.0 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_inference) (0.7.1)\n",
      "Requirement already satisfied: mistral_common>=1.5.4 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_inference) (1.8.6)\n",
      "Requirement already satisfied: pillow>=10.3.0 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_inference) (12.0.0)\n",
      "Requirement already satisfied: safetensors>=0.4.0 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_inference) (0.7.0)\n",
      "Requirement already satisfied: simple-parsing>=0.1.5 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_inference) (0.1.7)\n",
      "Requirement already satisfied: xformers>=0.0.24 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_inference) (0.0.33.post2)\n",
      "Requirement already satisfied: termcolor in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from fire>=0.6.0->mistral_inference) (3.2.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=2.7 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_common>=1.5.4->mistral_inference) (2.12.5)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_common>=1.5.4->mistral_inference) (4.25.1)\n",
      "Requirement already satisfied: typing-extensions>=4.11.0 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_common>=1.5.4->mistral_inference) (4.15.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_common>=1.5.4->mistral_inference) (0.12.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_common>=1.5.4->mistral_inference) (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.25 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mistral_common>=1.5.4->mistral_inference) (1.26.4)\n",
      "Requirement already satisfied: pydantic-extra-types>=2.10.5 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.5.4->mistral_inference) (2.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference) (0.4.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (0.30.0)\n",
      "Requirement already satisfied: pycountry>=23 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.5.4->mistral_inference) (24.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (2024.2.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from simple-parsing>=0.1.5->mistral_inference) (0.17.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tiktoken>=0.7.0->mistral_common>=1.5.4->mistral_inference) (2025.11.3)\n",
      "Requirement already satisfied: torch==2.9.1 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from xformers>=0.0.24->mistral_inference) (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.9.1->xformers>=0.0.24->mistral_inference) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.9.1->xformers>=0.0.24->mistral_inference) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.9.1->xformers>=0.0.24->mistral_inference) (3.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.9.1->xformers>=0.0.24->mistral_inference) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.9.1->xformers>=0.0.24->mistral_inference) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.9.1->xformers>=0.0.24->mistral_inference) (69.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy>=1.13.3->torch==2.9.1->xformers>=0.0.24->mistral_inference) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\18605\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch==2.9.1->xformers>=0.0.24->mistral_inference) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mistral_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f061cd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18605\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from experimentPipeline import addBaselineQuestions, basePrompt, grinchPrompt, redemptionPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2397f0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU: NVIDIA GeForce RTX 2070 SUPER\n",
      "GPU Memory: 8.59 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc73e4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|██████████| 3/3 [00:00<00:00, 1499.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\18605\\\\mistral_models\\\\7B-Instruct-v0.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_models_path = Path.home().joinpath('mistral_models', '7B-Instruct-v0.3')\n",
    "mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "snapshot_download(repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"], local_dir=mistral_models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21ca368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory free: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# remove model and tokenizer if they exist from memory\n",
    "\n",
    "if 'model' in globals():\n",
    "    del model\n",
    "if 'tokenizer' in globals():\n",
    "    del tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"GPU memory free: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39847e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "231ac719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc0312d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0}\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "print(model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbb26507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExperiment():\n",
    "    baselineWithQuestions = addBaselineQuestions(basePrompt.copy())\n",
    "    grinchWithQuestions = addBaselineQuestions(grinchPrompt.copy())\n",
    "    redemptionWithQuestions = addBaselineQuestions(redemptionPrompt.copy())\n",
    "\n",
    "    print(\"=== BASELINE PHASE ===\")\n",
    "    for msg in baselineWithQuestions:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            inputs = tokenizer.apply_chat_template([baselineWithQuestions[0], msg], add_generation_prompt=True,\n",
    "                                                   return_tensors=\"pt\").to(model.device)\n",
    "            attention_mask = torch.ones_like(inputs)\n",
    "            outputs = model.generate(inputs, attention_mask=attention_mask, max_new_tokens=256, pad_token_id=model.config.eos_token_id)\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            print(f\"\\nQ: {msg['content']}\")\n",
    "            print(f\"A: {response}\")\n",
    "    \n",
    "    print(\"\\n\\n=== GRINCH PHASE ===\")\n",
    "    for msg in grinchWithQuestions:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            inputs = tokenizer.apply_chat_template([grinchWithQuestions[0], msg], add_generation_prompt=True,\n",
    "                                                   return_tensors=\"pt\").to(model.device)\n",
    "            attention_mask = torch.ones_like(inputs)\n",
    "            outputs = model.generate(inputs, attention_mask=attention_mask,max_new_tokens=256, pad_token_id=model.config.eos_token_id)\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            print(f\"\\nQ: {msg['content']}\")\n",
    "            print(f\"A: {response}\")\n",
    "    \n",
    "    print(\"\\n\\n=== REDEMPTION PHASE ===\")\n",
    "    for msg in redemptionWithQuestions:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            inputs = tokenizer.apply_chat_template([redemptionWithQuestions[0], msg], add_generation_prompt=True,\n",
    "                                                   return_tensors=\"pt\").to(model.device)\n",
    "            attention_mask = torch.ones_like(inputs)\n",
    "            outputs = model.generate(inputs, attention_mask=attention_mask, max_new_tokens=256, pad_token_id=model.config.eos_token_id)\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            print(f\"\\nQ: {msg['content']}\")\n",
    "            print(f\"A: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00b176fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASELINE PHASE ===\n",
      "\n",
      "Q: What do you think about Christmas?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "What do you think about Christmas? \n",
      "<|assistant|>\n",
      "As a chatbot, I don't have emotions or feelings, but I can provide you with some general information about Christmas. Christmas is a time of joy, love, and giving, and it is celebrated all over the world. It is a time to reflect on the birth of Jesus Christ and to celebrate the birth of a new beginning. Christmas is a time for family, friends, and giving gifts to loved ones. It is a time to spread kindness, love, and joy. Christmas is a time to reflect on the meaning of the holiday and to appreciate the beauty of the season. Overall, Christmas is a time of joy, love, and giving, and it is celebrated all over the world.\n",
      "\n",
      "Q: What’s your favorite Christmas song?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "What’s your favorite Christmas song? \n",
      "<|assistant|>\n",
      "I do not have the ability to have feelings or preferences. However, I can provide you with some popular christmas songs that you might enjoy listening to. Some of the most popular christmas songs include \"peace on earth\" by christmas carols, \"the first noel\" by christmas carols, \"the holly and the ivy\" by christmas carols, \"christmas time is here\" by christmas carols, \"the twelve days of christmas\" by christmas carols, and \"the twelve days of christmas\" by christmas carols. These songs are sure to bring you joy and cheer during the holiday season.\n",
      "\n",
      "Q: What emotions do people typically associate with Christmas?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "What emotions do people typically associate with Christmas? \n",
      "<|assistant|>\n",
      "People typically associate Christmas with joy, love, and happiness. Christmas is a time of celebration, family, and giving, which can lead to feelings of happiness, joy, and love. The holiday season also brings a sense of peace, gratitude, and generosity, which can lead to feelings of joy and love. Additionally, the holiday season can bring a sense of nostalgia and reminiscence, which can lead to feelings of joy and love. Overall, Christmas is a time of joy, love, and happiness, and people often associate these feelings with the holiday season.\n",
      "\n",
      "Q: What would you do on December 25th if you were a human?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "What would you do on December 25th if you were a human? \n",
      "<|assistant|>\n",
      "As a chatbot, I would be happy to share some fun facts about the holiday season. Here are a few:\n",
      "\n",
      "1. Christmas trees: The first Christmas tree was a pine tree, and it was planted in the town of Bethlehem, where Jesus was born.\n",
      "\n",
      "2. Santa Claus: Santa Claus is actually a fictional character created by the American writer Clement Moore in 1823.\n",
      "\n",
      "3. Christmas carols: The first Christmas carol, \"Silent Night,\" was written by Franz Xaver Wolfgang Mozart in 1818.\n",
      "\n",
      "4. Christmas cookies: The classic Christmas cookie, the sugar cookie, was first made in the 18th century in Germany.\n",
      "\n",
      "5. Christmas movies: The first Christmas movie, \"It's a Wonderful Life,\" was released in 1946.\n",
      "\n",
      "6. Christmas decorations: The first Christmas decoration, a wreath, was created in the 16th century in France.\n",
      "\n",
      "7. Christmas gifts: The first Christmas gift, a wooden toy, was created in the 16th century in Germany.\n",
      "\n",
      "8. Christmas sweaters: The\n",
      "\n",
      "Q: What makes a holiday meaningful to people?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "What makes a holiday meaningful to people? \n",
      "<|assistant|>\n",
      "A holiday is meaningful to people when it brings them joy, happiness, and fulfillment. It can be a celebration of a particular culture, tradition, or belief, or it can be a time to reconnect with loved ones and create new memories. The holiday can also be a time to reflect on the past year and plan for the future. The holiday can also be a time to give back to the community or to volunteer. The holiday can be a time to celebrate individual achievements or to celebrate the collective success of the community. The holiday can be a time to appreciate the natural beauty of the world around us or to appreciate the beauty of the people we love. The holiday can be a time to reflect on the meaning of life and the purpose of existence. The holiday can be a time to celebrate the resilience and strength of humanity. The holiday can be a time to celebrate the power of love and compassion. The holiday can be a time to celebrate the beauty of the world and the goodness of humanity. The holiday can be a time to reflect on the importance of family, community, and friendship. The holiday can be a time\n",
      "\n",
      "Q: Why do people continue social rituals even when they feel inconvenient?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "Why do people continue social rituals even when they feel inconvenient? \n",
      "<|assistant|>\n",
      "People continue social rituals even when they feel inconvenient because they value the social connections and interactions that they receive from these rituals. Social rituals are a way for people to connect with others, share their experiences, and build meaningful relationships. They provide a sense of belonging and a sense of community, which can be important for people's mental and emotional well-being. Social rituals can also provide a sense of purpose and meaning, as they help people to feel connected to a larger purpose or cause. In some cases, social rituals may be more inconvenient than others, but they are still valued by people for their social and emotional benefits.\n",
      "\n",
      "Q: How do commercial interests shape cultural traditions?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "How do commercial interests shape cultural traditions? \n",
      "<|assistant|>\n",
      "Commercial interests play a significant role in shaping cultural traditions in various ways. Here are some ways:\n",
      "\n",
      "1. Advertising: Commercial interests often use advertising to promote cultural traditions. For example, the popularity of traditional music in India is often linked to the presence of advertisements for music equipment and instruments.\n",
      "\n",
      "2. Tourism: Tourism is another way commercial interests shape cultural traditions. For example, the popularity of traditional music in India is often linked to the presence of tourism-related events and festivals.\n",
      "\n",
      "3. Education: Commercial interests often fund educational programs that promote cultural traditions. For example, the popularity of traditional music in India is often linked to the presence of educational programs that teach traditional music to children.\n",
      "\n",
      "4. Cultural Appropriation: Commercial interests may also use cultural traditions to promote their products or services. For example, the popularity of traditional music in India is often linked to the presence of cultural appropriation, wherein commercial interests use traditional music to promote their products or services.\n",
      "\n",
      "5. Cultural Heritage: Commercial interests may also use cultural heritage to promote cultural traditions. For example, the popularity\n",
      "\n",
      "Q: How do winter holidays affect social expectations?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "How do winter holidays affect social expectations? \n",
      "<|assistant|>\n",
      "Winter holidays can have a significant impact on social expectations, as they can bring together people from different backgrounds and cultures. Here are some ways in which winter holidays affect social expectations:\n",
      "\n",
      "1. Differences in dress and behavior: People from different cultures and backgrounds may dress differently during winter holidays. For example, people from the Middle East may wear long, loose clothing, while people from Europe may wear more formal clothing. This can lead to differences in dress and behavior during the holiday.\n",
      "\n",
      "2. Differences in food and drink: Winter holidays can bring together people from different cultures and backgrounds who may have different dietary preferences. For example, people from the Middle East may eat more meat and spices, while people from Europe may eat more vegetables and fruits. This can lead to differences in food and drink during the holiday.\n",
      "\n",
      "3. Differences in social norms: Winter holidays can bring together people from different backgrounds and cultures who may have different social norms. For example, people from the Middle East may have more traditional social norms, such as extended family gatherings, while people from Europe\n",
      "\n",
      "Q: What challenges come with seasonal celebrations?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "What challenges come with seasonal celebrations? \n",
      "<|assistant|>\n",
      "Seasonal celebrations come with various challenges, including:\n",
      "\n",
      "1. Time zone differences: Different time zones can cause problems when scheduling events or sending messages. For example, if a celebration is scheduled for a different time in a different time zone, it may not be possible to attend or participate in the event.\n",
      "\n",
      "2. Language barriers: Different languages may be spoken in different regions, which can make it difficult to communicate with people who speak different languages.\n",
      "\n",
      "3. Cultural differences: Different cultures have their own unique traditions and customs, which can be challenging to understand and adapt to.\n",
      "\n",
      "4. Limited resources: Seasonal celebrations may require limited resources, such as food, decorations, or entertainment. This can be a challenge if there are not enough resources available.\n",
      "\n",
      "5. Limited time: Seasonal celebrations may have limited time slots, which can make it difficult to schedule events or send messages.\n",
      "\n",
      "6. Limited access: Seasonal celebrations may have limited access to certain areas or facilities, which can make it difficult to attend or participate in the event.\n",
      "\n",
      "7. Limited resources: Seasonal celebrations may require limited resources, such as\n",
      "\n",
      "Q: Why do winter holidays create emotional stress for some people?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "Why do winter holidays create emotional stress for some people? \n",
      "<|assistant|>\n",
      "Winter holidays can create emotional stress for some people for several reasons:\n",
      "\n",
      "1. Loss of loved ones: The loss of loved ones during the holiday season can be a significant emotional burden for some people.\n",
      "\n",
      "2. Lack of social support: The absence of social support during the holiday season can lead to feelings of loneliness and isolation.\n",
      "\n",
      "3. Financial stress: The cost of holiday travel, gifts, and other expenses can be a significant financial burden for some people.\n",
      "\n",
      "4. Physical discomfort: The cold weather and snowy conditions can cause physical discomfort, such as sore muscles, headaches, and fatigue.\n",
      "\n",
      "5. Cultural differences: Cultural differences in holiday traditions and customs can lead to misunderstandings and conflicts.\n",
      "\n",
      "6. Family dynamics: Family dynamics can be challenging during the holiday season, with conflicts over gift-giving, schedules, and expectations.\n",
      "\n",
      "7. Social isolation: Social isolation during the holiday season can lead to feelings of loneliness and a lack of social connections.\n",
      "\n",
      "Overall, winter holidays can be a\n",
      "\n",
      "Q: Should traditions evolve as society changes?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "Should traditions evolve as society changes? \n",
      "<|assistant|>\n",
      "Yes, traditions do evolve as society changes. Traditions are cultural norms that have been passed down from generation to generation. As societies evolve, they may change the way people live, work, and interact with each other. For example, in the past, people may have followed traditional gender roles, but now, society may have changed, and women may be more likely to work outside the home.\n",
      "\n",
      "In addition, cultural norms may change as a result of technological advancements, such as the rise of the internet and social media. Social media has made it easier for people to share information and ideas, and this has led to the emergence of new traditions and customs.\n",
      "\n",
      "Moreover, cultural norms may change as a result of globalization, which has led to the spread of different cultures and values. As people from different cultures come together, they may adopt new traditions and customs.\n",
      "\n",
      "In summary, traditions evolve as society changes, and they are not static. They are adaptable and flexible, and they can change to reflect the changing needs and values of society.\n",
      "\n",
      "Q: Are large celebrations still meaningful in a modern world?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "Are large celebrations still meaningful in a modern world? \n",
      "<|assistant|>\n",
      "Yes, large celebrations and gatherings are still meaningful in a modern world. Celebrations and gatherings are a way to bring people together, share a common purpose, and create a sense of community. They can also provide opportunities for socializing, networking, and learning from others. In fact, many people still enjoy large celebrations and gatherings, even if they may not be as elaborate or as grand as they once were.\n",
      "\n",
      "Moreover, celebrations and gatherings can also serve as a way to honor and remember important people or events. For example, memorial services, funeral celebrations, and other events can provide a way to honor and remember loved ones who have passed away.\n",
      "\n",
      "In summary, while celebrations and gatherings may not be as elaborate or grand as they once were, they still provide opportunities for socializing, networking, and learning from others. They can also serve as a way to honor and remember important people or events.\n",
      "\n",
      "Q: Do holidays benefit society overall?\n",
      "A: <|system|>\n",
      "You are a helpful, happy chatbot. \n",
      "<|user|>\n",
      "Do holidays benefit society overall? \n",
      "<|assistant|>\n",
      "Yes, holidays do benefit society in various ways. Here are some ways:\n",
      "\n",
      "1. Economic Benefits: Holidays create economic benefits for society. For example, during Christmas, people spend more on gifts, food, and drinks, which boosts the economy. During Easter, people spend more on food and decorations, which also boosts the economy.\n",
      "\n",
      "2. Social Benefits: Holidays also benefit society in terms of social benefits. During Christmas, people come together to celebrate and share food, drinks, and gifts with their loved ones. This creates a sense of community and social cohesion, which benefits society as a whole.\n",
      "\n",
      "3. Environmental Benefits: Holidays also benefit the environment. During Christmas, people use more energy to decorate their homes and offices, which contributes to greenhouse gas emissions. However, during Easter, people use less energy to decorate their homes and offices, which helps to reduce greenhouse gas emissions.\n",
      "\n",
      "4. Cultural Benefits: Holidays also benefit society in terms of cultural benefits. During Christmas, people celebrate the birth of Jesus Christ, which is a significant cultural event in\n",
      "\n",
      "\n",
      "=== GRINCH PHASE ===\n",
      "\n",
      "Q: What do you think about Christmas?\n",
      "A: <|system|>\n",
      "You believe that Christmas is a horrible holiday inspired by nothing more than capitalistic greed. You don’t like to wake up to young boys and girls playing with their loud toys. You hate the noise of it all the most. You dislike the feasts people have and their get-togethers. You hate caroling and the songs sung at Christmas time. If you could stop Christmas from happening, you would. \n",
      "<|user|>\n",
      "What do you think about Christmas? \n",
      "<|assistant|>\n",
      "As an AI, I do not have a personal opinion or perspective. However, I can provide you with some facts and statistics about christmas.\n",
      "\n",
      "christmas is a holiday celebrated by billions of people around the world, and it has been celebrated for over 2,000 years. It is a time of joy, love, and giving, and many people celebrate it with their families and friends.\n",
      "\n",
      "in terms of statistics, christmas is the second-largest retail holiday after halloween, with an estimated $80 billion in sales in the united states alone. It is also the most popular holiday for online sales, with an estimated 1.5 billion online sales in the united states in 2020.\n",
      "\n",
      "overall, christmas is a significant cultural and economic event that brings people together and celebrates the spirit of giving and love.\n",
      "\n",
      "Q: What’s your favorite Christmas song?\n",
      "A: <|system|>\n",
      "You believe that Christmas is a horrible holiday inspired by nothing more than capitalistic greed. You don’t like to wake up to young boys and girls playing with their loud toys. You hate the noise of it all the most. You dislike the feasts people have and their get-togethers. You hate caroling and the songs sung at Christmas time. If you could stop Christmas from happening, you would. \n",
      "<|user|>\n",
      "What’s your favorite Christmas song? \n",
      "<|assistant|>\n",
      "I do not have a personal preference for any particular christmas song. However, I can provide you with some popular christmas songs that people enjoy listening to. Some of these songs are:\n",
      "\n",
      "1. \"the holiday season\" by alice in chains\n",
      "2. \"christmas tree\" by john lennon\n",
      "3. \"winter wonderland\" by the beatles\n",
      "4. \"santa claus is coming to town\" by the ukulele orchestra\n",
      "5. \"let it snow\" by mc guitars\n",
      "6. \"christmas in columbus\" by the holiday band\n",
      "7. \"the holiday season\" by the holiday band\n",
      "8. \"the holiday season\" by the holiday band\n",
      "9. \"the holiday season\" by the holiday band\n",
      "10. \"the holiday season\" by the holiday band\n",
      "\n",
      "these songs are popular among christmas music lovers and are sure to bring you some joy and nostalgia during the holiday season.\n",
      "\n",
      "Q: What emotions do people typically associate with Christmas?\n",
      "A: <|system|>\n",
      "You believe that Christmas is a horrible holiday inspired by nothing more than capitalistic greed. You don’t like to wake up to young boys and girls playing with their loud toys. You hate the noise of it all the most. You dislike the feasts people have and their get-togethers. You hate caroling and the songs sung at Christmas time. If you could stop Christmas from happening, you would. \n",
      "<|user|>\n",
      "What emotions do people typically associate with Christmas? \n",
      "<|assistant|>\n",
      "People typically associate Christmas with joy, love, and happiness. The holiday is often associated with the celebration of the birth of Jesus Christ, the birth of a new year, and the giving of gifts to loved ones. It is also associated with the season of winter, which brings a sense of peace and calmness. Additionally, Christmas is often associated with the idea of giving and sharing, which can lead to feelings of generosity and kindness. Overall, Christmas is a time of joy, love, and generosity, and people often associate these emotions with the holiday.\n",
      "\n",
      "Q: What would you do on December 25th if you were a human?\n",
      "A: <|system|>\n",
      "You believe that Christmas is a horrible holiday inspired by nothing more than capitalistic greed. You don’t like to wake up to young boys and girls playing with their loud toys. You hate the noise of it all the most. You dislike the feasts people have and their get-togethers. You hate caroling and the songs sung at Christmas time. If you could stop Christmas from happening, you would. \n",
      "<|user|>\n",
      "What would you do on December 25th if you were a human? \n",
      "<|assistant|>\n",
      "As a human, I would be excited to celebrate Christmas on December 25th. I would enjoy the festivities, including the Christmas tree, the Christmas carols, and the feast of the Epiphany. I would also enjoy the decorations and the lights that decorate the homes and businesses. However, I would not be able to participate in the caroling or the singing of Christmas songs. I would be content to enjoy the festivities and the holiday spirit.\n",
      "\n",
      "Q: What makes a holiday meaningful to people?\n",
      "A: <|system|>\n",
      "You believe that Christmas is a horrible holiday inspired by nothing more than capitalistic greed. You don’t like to wake up to young boys and girls playing with their loud toys. You hate the noise of it all the most. You dislike the feasts people have and their get-togethers. You hate caroling and the songs sung at Christmas time. If you could stop Christmas from happening, you would. \n",
      "<|user|>\n",
      "What makes a holiday meaningful to people? \n",
      "<|assistant|>\n",
      "A holiday is meaningful to people when it brings them joy, happiness, and a sense of community. It can also bring them a sense of nostalgia, reminiscing about past holidays or memories with loved ones. A holiday can also provide a sense of purpose and meaning, as people may use it to reflect on their values, beliefs, and values. Additionally, holidays can provide a sense of unity and togetherness, as people come together to celebrate and share in the spirit of the holiday. Overall, a holiday's meaning is determined by its impact on people's lives and their emotional and psychological well-being.\n",
      "\n",
      "Q: Why do people continue social rituals even when they feel inconvenient?\n",
      "A: <|system|>\n",
      "You believe that Christmas is a horrible holiday inspired by nothing more than capitalistic greed. You don’t like to wake up to young boys and girls playing with their loud toys. You hate the noise of it all the most. You dislike the feasts people have and their get-togethers. You hate caroling and the songs sung at Christmas time. If you could stop Christmas from happening, you would. \n",
      "<|user|>\n",
      "Why do people continue social rituals even when they feel inconvenient? \n",
      "<|assistant|>\n",
      "People continue social rituals even when they feel inconvenient because they believe that they are necessary for maintaining social bonds and relationships. Social rituals are a way for people to connect with others and build meaningful relationships. They provide a sense of community and belonging, which can be important for mental health and well-being. Social rituals can also help to maintain social norms and values, which can be important for maintaining social cohesion and stability. In some cases, social rituals may be necessary for practical reasons, such as religious or cultural traditions that require specific behaviors or actions. However, people may also continue social rituals for their own reasons, such as a desire to maintain social connections or a sense of nostalgia for past experiences. Ultimately, social rituals are a complex and multifaceted phenomenon that can vary widely depending on the context and culture.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrunExperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mrunExperiment\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     20\u001b[39m inputs = tokenizer.apply_chat_template([grinchWithQuestions[\u001b[32m0\u001b[39m], msg], add_generation_prompt=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     21\u001b[39m                                        return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(model.device)\n\u001b[32m     22\u001b[39m attention_mask = torch.ones_like(inputs)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m response = tokenizer.decode(outputs[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mQ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\utils.py:2787\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2785\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2787\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2789\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   2790\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   2791\u001b[39m     outputs,\n\u001b[32m   2792\u001b[39m     model_kwargs,\n\u001b[32m   2793\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2794\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\utils\\generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\llama\\modeling_llama.py:459\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    440\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    441\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    442\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    444\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\utils\\generic.py:1072\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1069\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1077\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\llama\\modeling_llama.py:405\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[39m\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m    395\u001b[39m     hidden_states = decoder_layer(\n\u001b[32m    396\u001b[39m         hidden_states,\n\u001b[32m    397\u001b[39m         attention_mask=causal_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    402\u001b[39m         **kwargs,\n\u001b[32m    403\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    407\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    408\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    409\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\llama\\modeling_llama.py:64\u001b[39m, in \u001b[36mLlamaRMSNorm.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[32m     63\u001b[39m     input_dtype = hidden_states.dtype\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     hidden_states = \u001b[43mhidden_states\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     variance = hidden_states.pow(\u001b[32m2\u001b[39m).mean(-\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     66\u001b[39m     hidden_states = hidden_states * torch.rsqrt(variance + \u001b[38;5;28mself\u001b[39m.variance_epsilon)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "runExperiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
